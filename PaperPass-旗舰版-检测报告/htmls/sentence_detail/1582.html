<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>详细报告语句详情</title>
    <link href="../css/bootstrap.css" rel="stylesheet" />
    <link href="../css/style.css" rel="stylesheet" />
    <style type="text/css">
        .content-tips .paper-section{margin-bottom:0;min-width:450px;}
    </style>
</head>
<body>
<span id="gototop"></span>
<div>
    <div class="paper-txt P30">
        <div class="paper-section" style="margin-bottom:0;">
            <div class="font-bold MT5">
                该句相似度：<span class="g-font-color orange similarNum">56%</span>
            </div>
            <div class="MT30">
                <p class="font-bold">您的语句：</p>
                <span>回顾LDA的优化准则，它要求目标最小化类内散度矩阵值，同时最大化类间散度矩阵值。</span>
            </div>
        </div>
    </div>
    <div>
        <div class="tab-A">
            <ul class="tab-A-ul clearfix" tab-a="ul">
                <li class="active" data-id="学术期刊,学位论文,学术会议,书籍数据,互联网,自建库,all">
                    <span class="tab-text">综合</span>
                    <span class="tab-superscript">16</span>
                </li>
                <li data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local">
                    <span class="tab-text">本地库</span>
                    <span class="tab-superscript">16</span>
                </li>
                <li data-id="互联网,5">
                    <span class="tab-text">互联网</span>
                    <span class="tab-superscript">0</span>
                </li>
            </ul>
        </div>
        <div class="none" tab="section" data-id="tab">
            <div class="tab-B clearfix">
                <div class="paper-section P30 PB0 clearfix">
                    <span class="tab-B-span pull-left">本地库</span>
                    <ul class="tab-B-ul pull-left clearfix" tab-b="ul">
                        <li class="active" data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local">
                            <span class="tab-text">全部</span>
                            <span class="tab-superscript">16</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术期刊,1">
                            <span class="tab-text">期刊</span>
                            <span class="tab-superscript">8</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学位论文,2">
                            <span class="tab-text">学位</span>
                            <span class="tab-superscript">7</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术会议,3">
                            <span class="tab-text">会议</span>
                            <span class="tab-superscript">1</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,书籍数据,4">
                            <span class="tab-text">图书</span>
                            <span class="tab-superscript">0</span>
                                                    </li>
                                            </ul>
                </div>
                <div class="g-line-row MT30 tab-pane-line"></div>
            </div>
        </div>
        <div class="content-tips">
            <div class="tab-content none" tab="section" data-id="1">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在期刊库共找出相似内容：<span>8</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                </div>
            </div>

            <div class="tab-content none" tab="section" data-id="2">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在学位库共找出相似内容：<span>7</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="3">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在会议库共找出相似内容：<span>1</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="4">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在图书库中没有找到与此句话相似的内容                    <p>
                    <div class="pull-right">
                                            </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="5">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在互联网库中没有找到与此句话相似的内容                    <p>
                    <div class="pull-right">
                                            </div>
                </div>
            </div>
            <!-- 自建库 -->
            <div class="tab-content none" tab="section" data-id="6">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在自建库中没有找到与此句话相似的内容                    <p>
                    <div class="pull-right">
                                            </div>
                </div>
            </div>
                        <div class="tab-content" tab="section" data-id="all">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在本地库和互联网库共找出相似内容：<span>16</span>个
                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>

                    </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="local">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在本地库共找出相似内容：<span>16</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                </div>
            </div>
        </div>



                <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">1</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">56%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA的优<span class="g-underline-text">化</span>准则，它要求目标<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，<span class="g-underline-text">同时</span><span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">：(1)LDA[11。LDA通过<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">同时</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>来获得</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            这6种数据库进行了详细的描述。图2．1显示了前五类的样例图像。表2．1数据库描述2．4．2比较算法为了验证本章节提出的算法SLDA的有效性，采用以下算法进行比较<span class="g-font-color green">：(1)LDA[11。LDA通过最大化类间散度矩阵，同时最小化类内散度矩阵来获得</span>映射矩阵。本质上，LDA是一种监督特征提取算法，不能利用无标签的训练样本。(2)SDA[46】                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于子空间的特征提取与融合算法研究》<br><b>作者：</b>王胜<br><b>分类号：</b>TP391.4<br><b>学科专业：</b>控制科学与工程<br><b>授予学位：</b>博士<br><b>导师姓名：</b>陆建峰<br><b>学位授予单位：</b>南京理工大学<br><b>学位年度：</b>2016<br><b>关键词：</b>模式识别 特征提取 融合算法 子空间法
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">2</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">55%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优<span class="g-underline-text">化</span>准则，它要求目标<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，<span class="g-underline-text">同时</span><span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">差异。LDA算法<span class="g-underline-text">的</span>目<span class="g-underline-text">的</span>是通过<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span><span class="g-underline-text">同时</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，使得在</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            为主成分矩阵，wi也就是这组数据的主分量。2.1.2线性鉴别分析线性鉴别分析（LDA）[7]算法考虑样本的全局结构，将高维的数据投影到低维的空间中，最优的表达出类别间的<span class="g-font-color green">差异。LDA算法的目的是通过最大化类间散度矩阵的同时最小化类内散度矩阵，使得在</span>投影时同类的样本相互靠拢，异类的样本相互远离，以便更好的进行识别和分类。给定样本集12NS分别                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于鉴别分析的类不平衡学习》<br><b>作者：</b>李敏<br><b>学科专业：</b>""<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>荆晓远<br><b>学位授予单位：</b>南京邮电大学<br><b>学位年度：</b>2013<br><b>关键词：</b>类不平衡 鉴别分析 图像特征提取与识别 主动学习 核方法
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">3</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">54%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优<span class="g-underline-text">化</span>准则，它要求目标<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，<span class="g-underline-text">同时</span><span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">每个样本与<span class="g-underline-text">类</span>之<span class="g-underline-text">间</span><span class="g-underline-text">的</span>离<span class="g-underline-text">散</span><span class="g-underline-text">度</span>。为了<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span><span class="g-underline-text">同时</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            样本的相关联度或称冗余度）。类间散度矩阵从宏观上描述了所有类和总体之间的离散冗余程度。而类内散度矩阵Sw中类内元素的均值刻画的是类的特性，描述的是<span class="g-font-color green">每个样本与类之间的离散度。为了最大化类间散度矩阵的同时最小化类内散度矩阵，</span>我们引入如下Fisher判别准则：其中W为投影方向。Fisher线性判别分析就是选取使得JWfisher()达到最大值时的矢量                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于偏最小二乘的人脸识别算法研究》<br><b>作者：</b>步文斌<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>应用数学<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>杨丹<br><b>学位授予单位：</b>重庆大学<br><b>学位年度：</b>2013<br><b>关键词：</b>偏最小二乘 人脸识别算法 分类效果 鲁棒性
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">4</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">54%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优<span class="g-underline-text">化</span>准则，它要求目标<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵值，<span class="g-underline-text">同时</span><span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">分析<span class="g-underline-text">的</span>模糊紧性分离性聚<span class="g-underline-text">类</span>算法标是<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">的</span><span class="g-underline-text">同时</span><span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>。因为</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            76，。78】常常被用来处理散布矩阵奇异性问题。2．1．2线性判别分析引导的自适应子空间硬c．均值聚类算法众所周知，利用散布矩阵，HCM的目标函数可以表示为第二章基于模糊线性判别<span class="g-font-color green">分析的模糊紧性分离性聚类算法标是最小化类内散度的同时最大化类间散度。因为</span>LDA的目标也是最大化trace(Sb)的同时最小化trace(Sw)，LDA与HCM的目标函数是一致的。                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《自适应判别降维模糊聚类算法研究》<br><b>作者：</b>支晓斌<br><b>学科专业：</b>模式识别与智能系统<br><b>授予学位：</b>博士<br><b>导师姓名：</b>范九伦<br><b>学位授予单位：</b>西安电子科技大学<br><b>学位年度：</b>2013
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">5</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">49%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA的优<span class="g-underline-text">化</span>准则，它要求<span class="g-underline-text">目标</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">两个<span class="g-underline-text">目标</span>，c<span class="g-underline-text">值</span>越大，意味着<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>越重要(相对于<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>)</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            与近万方数据第3期田玉敏等：判男4近邻保持嵌入人脸识别27邻保持嵌入算法中M的求解方法与意义均相同；参数C是正实数，用于平衡最大化类间散度和最小化类内散度<span class="g-font-color green">两个目标，c值越大，意味着最小化类内散度越重要(相对于最大化类间散度)</span>；S。是类间散度矩阵；Sw是类内散度矩阵，定义为凡。为第i个模式类的                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《判别近邻保持嵌入人脸识别》<br><b>作者：</b>田玉敏 云艳娥 马天骏<br><b>作者单位：</b>西安电子科技大学计算机学院,陕西西安,710071<br><b>参考文献：</b>8篇<br><b>被引次数：</b>1次（统计时间：2015年8月）<br><b>页码：</b>P24—P28,98<br><b>分类号：</b>TP391.4<br><b>机标分类号：</b>TP3 TN9<br><b>基金项目：</b>陕西省自然科学基础研究计划资助项目(2010JM8011)<br><b>期刊名称：</b>《西安电子科技大学学报（自然科学版）》<br><b>出版时间：</b>2011年3期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1001-2400<br><b>关键词：</b>人脸识别 近邻保持嵌入 最大散度差准则<br><b>摘要：</b>针对普通近邻保持嵌入算法侧重保持样本的局部结构,而没有考虑样本的类判别信息以及小样本问题,提出了一种新的人脸识别算法--判别近邻保持嵌入算法.在近邻保持嵌入算法的基础上,将最大散度差准则引入到其目标函数中.在嵌入低维空间后,类内样本保持它们固有的近邻几何结构关系,而类间样本彼此分离,能够充分提取具有判别力的特征.在AT&amp;T人脸数据库上进行的对比实验表明,与主成分分析、线性判别分析以及近邻保持嵌入算法相比,判别近邻保持嵌入算法的最高识别率分别提高了15.35%、6.47%和6.94%;在Yale人脸数据库上进行的对比实验表明,判别近邻保持嵌入算法的最高识别率分别提高了20.27%、5.63%和2.27%.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">6</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">49%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优<span class="g-underline-text">化</span>准则，它要求目标最小<span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，<span class="g-underline-text">同时</span><span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">算法中<span class="g-underline-text">的</span>相似<span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>重构NSA<span class="g-underline-text">的</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，使得在<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span><span class="g-underline-text">同时</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            ：提出了一种局部非参数子空间分析算法（LocalNonparametricSubspaceAnalysis，LNSA），将其应用在人脸识别中。LNSA算法结合了非参数子空间算法（NonparametricSubspaceAnalysis，NSA）与局部保留投影算法（LocalityPreservingProjection，LPP）。它利用LPP<span class="g-font-color green">算法中的相似度矩阵重构NSA的类内散度矩阵，使得在最大化类间散度矩阵的同时</span>保留了类的局部结构。在ORL人脸库和XM2VTS人脸库上作了实验并证明LNSA方法要优于                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《局部非参数子空间分析在人脸识别中的应用》<br><b>作者：</b>程强 陈秀宏<br><b>作者单位：</b>江南大学 数字媒体学院,江苏 无锡,214122<br><b>参考文献：</b>13篇<br><b>页码：</b>P141—P144<br><b>页数：</b>4页<br><b>分类号：</b>TP391<br><b>机标分类号：</b>TP3 TN9<br><b>基金项目：</b>江苏省科研创新计划项目(No.CXLX11_04910)；中央高校基本科研业务费专项资金资助(No.JUSRT211A70)。<br><b>期刊名称：</b>《计算机工程与应用》<br><b>出版时间：</b>2014年3期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1002-8331<br><b>关键词：</b>人脸识别 非参数子空间分析 局部保留投影 局部鉴别分析 局部非参数子空间分析<br><b>摘要：</b>提出了一种局部非参数子空间分析算法（Local Nonparametric Subspace Analysis，LNSA），将其应用在人脸识别中。LNSA算法结合了非参数子空间算法（Nonparametric Subspace Analysis，NSA）与局部保留投影算法（Locality Preserving Projection，LPP）。它利用LPP算法中的相似度矩阵重构NSA的类内散度矩阵，使得在最大化类间散度矩阵的同时保留了类的局部结构。在ORL人脸库和XM2VTS人脸库上作了实验并证明LNSA方法要优于其他方法。
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">7</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">48%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优<span class="g-underline-text">化</span>准则，它要求<span class="g-underline-text">目标</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">的</span><span class="g-underline-text">目标</span>，C<span class="g-underline-text">值</span>越大意味着<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>越重要(相对于<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>而言)</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            问题．修正的Fisher鉴别准则是，选择使得类间散度与类内散度的差达到最大值的向量作为最优投影方向，其中c是一个正常数，用来平衡最大化类间散度和最小化类内散度两个不同<span class="g-font-color green">的目标，C值越大意味着最小化类内散度越重要(相对于最大化类间散度而言)</span>．寻求使得式(11)达到最大值的投影方向等价于求解下述这样一个二次规划问题罂愁山(叫"=                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《最大散度差和大间距线性投影与支持向量机》<br><b>作者：</b>宋枫溪 范程科 杨静宇 刘树海<br><b>作者单位：</b>南京理工大学计算机系,南京,210094；炮兵学院一系,合肥,230031<br><b>参考文献：</b>6篇<br><b>被引次数：</b>49次（统计时间：2015年8月）<br><b>页码：</b>P890—P896<br><b>页数：</b>7页<br><b>分类号：</b>TP39<br><b>机标分类号：</b>TP3 TD8<br><b>基金项目：</b>国家自然科学基金(60072034)<br><b>期刊名称：</b>《自动化学报》<br><b>出版时间：</b>2004年6期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>0254-4156<br><b>关键词：</b>最大散度差 大间距线性投影 支持向量机 Fisher鉴别准则 线性鉴别分析 人脸识别<br><b>摘要：</b>首先对Fisher鉴别准则作了必要的修正,并基于新的鉴别准则设计了最大散度差分类器;然后探讨了当参数C趋向无穷大时,最大散度差分类器的极限情况,得到了大间距线性投影分类器;最后通过分析说明,大间距线性投影分类器实际上是在模式样本线性可分的条件下,线性支持向量机的一种特殊情况.在ORL和NUST603人脸库上的测试结果表明,最大散度差分类器和大间距线性投影分类器可以与线性支持向量机、不相关线性鉴别分析相媲美,优于Foley-Sammon鉴别分析方法.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">8</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">48%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优<span class="g-underline-text">化</span>准则，它要求目标<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵值，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">最大</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>差<span class="g-underline-text">的</span>模式<span class="g-underline-text">间</span><span class="g-underline-text">的</span>相似性，通过<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>和<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>，解决</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            散度作为判别标准，能在一定程度上克服Fisher准则类内散布矩阵奇异性问题【9J。本文首先提出基于最大散度差的聚clusteringalgo削瑚)，然后引入模糊理论对最大散度差准则进行模糊化，提出基于<span class="g-font-color green">最大散度差的模式间的相似性，通过最小化类内散度和最小化类间散度，解决</span>试车数据集中样本模式差异小的问题，进一步提高试车数据聚类的准确性。1基本概念1．1散布                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《LRE试车数据挖掘中基于最大散度差的模糊聚类分析方法》<br><b>作者：</b>王珉 胡茑庆 秦国军<br><b>作者单位：</b>国防科技大学机电工程与自动化学院,湖南长沙,410073<br><b>参考文献：</b>12篇<br><b>页码：</b>P164—P168<br><b>分类号：</b>V434.21<br><b>机标分类号：</b>V26 TP3<br><b>基金项目：</b>国家自然科学基金赍助项目(50675219);湖南省杰出青年科学基金资助项目(08JJ1088)<br><b>期刊名称：</b>《国防科技大学学报》<br><b>出版时间：</b>2011年3期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1001-2486<br><b>关键词：</b>液体火箭发动机 试车数据 数据挖掘 最大散度差准则 软划分 模糊聚类<br><b>摘要：</b>在对液体火箭发动机试车数据进行聚类分析时,为解决故障数据样本与正常样本类间差异不大的问题,引入最大散度差准则,提出基于最大散度差的聚类算法MSD-CA.该算法以散度度量样本间的相似性,使样本的类内散度最小化和类间散度最大化同时进行.在此基础上,应用模糊理论对最大散度差准则进行模糊化,提出基于最大散度差的模糊聚类算法MSD-FCA,用于对试车样本进行“软划分”,以提高聚类的正确性.实验结果证明了MSD-FCA的有效性.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">9</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">48%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA的优<span class="g-underline-text">化</span>准则，它要求<span class="g-underline-text">目标</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">个<span class="g-underline-text">目标</span>，c<span class="g-underline-text">值</span>越大，意味着<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>越重要(相对于<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            X。瓦、毛分别为投影变换后的类问散度和类内散度，有：最大散度差准则函数定义为：其中，c是正常数，用来平衡最大化类间散度和最小化类内散度2<span class="g-font-color green">个目标，c值越大，意味着最小化类内散度越重要(相对于最大化类间散度</span>)。由式(3)和式(4)可以将式(5)变换成：其中，品一CSw是参数为                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于判别等度规映射的人脸识别》<br><b>作者：</b>邵艳玲 葛玻 宋书中<br><b>作者单位：</b>河南科技大学电子信息工程学院,河南洛阳,471003；河南科技大学电子信息工程学院,河南洛阳471003；洛阳理工学院,河南洛阳471023<br><b>参考文献：</b>11篇<br><b>页码：</b>P14—P17<br><b>分类号：</b>TP391<br><b>机标分类号：</b>TP3 TP1<br><b>基金项目：</b>河南省高等学校青年骨干教师资助计划基金资助项目(2011GGJS-173)<br><b>期刊名称：</b>《计算机工程》<br><b>出版时间：</b>2012年16期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1000-3428<br><b>关键词：</b>等度规映射 人脸识别 特征提取 最大散度差准则<br><b>摘要：</b>等度规映射算法旨在最大限度地保持样本间距离,没有考虑样本的类判别信息.针对该问题,提出一种基于判别等度规映射的人脸识别算法.在等度规映射算法的基础上,引入最大散度差准则,得到优化的目标函数.在嵌入低维子空间后,同类样本保持其固有的近邻几何结构关系,不同类近邻样本则彼此远离.在ORL数据库上的实验结果验证了该算法的有效性.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">10</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">48%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA的优<span class="g-underline-text">化</span>准则，它要求目标<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">定义<span class="g-underline-text">类</span><span class="g-underline-text">内</span>和<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，并通过<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>、<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>以求得最优</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            计算机系，浙江金华321004；2．上海交通大学图像处理与模式识别研究所，上海200240)摘要：提出了一种新的有监督降维方法：拉普拉斯最大最小判别分析(LaplacianMinMaxDiscriminantAnalysis，LMMDA)．LMMDA通过样本空间中成对点之间的距离<span class="g-font-color green">定义类内和类间散度矩阵，并通过最小化类内散度、最大化类间散度以求得最优</span>投影矩阵．在LMMDA最优子空间中，类内样本更为紧致，类间样本更为松弛．样本集的结构信息包含                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《拉普拉斯最大最小判别分析及应用》<br><b>作者：</b>郑忠龙 杨杰<br><b>作者单位：</b>浙江师范大学计算机系,浙江金华,321004；上海交通大学图像处理与模式识别研究所,上海,200240<br><b>参考文献：</b>22篇<br><b>被引次数：</b>1次（统计时间：2015年8月）<br><b>页码：</b>P860—P864,859<br><b>分类号：</b>TP391.4<br><b>机标分类号：</b>O21 TN9<br><b>基金项目：</b>国家自然科学基金(60805001);国家863高技术研究发展计划(2007AA01Z164);浙江省自然科学基金(Y1090579)<br><b>期刊名称：</b>《电子学报》<br><b>出版时间：</b>2010年4期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>0372-2112<br><b>关键词：</b>降维 有监督学习 判别分析 拉普拉斯映射<br><b>摘要：</b>提出了一种新的有监督降维方法:拉普拉斯最大最小判别分析(Laplacian MinMax Discriminant Analysis,LMMDA).LMMDA通过样本空间中成对点之间的距离定义类内和类间散度矩阵,并通过最小化类内散度、最大化类间散度以求得最优投影矩阵.在LMMDA最优子空间中,类内样本更为紧致,类间样本更为松弛.样本集的结构信息包含在类内、类间的Laplacian矩阵,并可以对最优投影子空间加以控制.在多个数据集上的实验证明了该算法的有效性.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">11</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">48%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA的优<span class="g-underline-text">化</span>准则，它要求<span class="g-underline-text">目标</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">度</span>两个<span class="g-underline-text">目标</span>，C<span class="g-underline-text">值</span>越大意味着<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>越重要（相对于<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>）</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            XWY=。SB、SW分别变换投影变动后的类间散度矩阵和类内散度矩阵：等人提出的最大散度差准则函数其中：个中，C是正常数平衡用来均衡最大化类间散度和最小化类内散<span class="g-font-color green">度两个目标，C值越大意味着最小化类内散度越重要（相对于最大化类间散度）</span>。由式(4-12)和(4-13)可以将式(4-14)变换成以下其中：个中，                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于子空间的人脸识别算法研究》<br><b>作者：</b>云艳娥<br><b>分类号：</b>TP301.6<br><b>学科专业：</b>计算机系统结构<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>田玉敏<br><b>学位授予单位：</b>西安电子科技大学<br><b>学位年度：</b>2010<br><b>关键词：</b>子空间 人脸识别 生物特征识别 流形学习 拉普拉斯特征映射
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">12</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">47%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA的优<span class="g-underline-text">化</span>准则，它要求<span class="g-underline-text">目标</span><span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>矩阵<span class="g-underline-text">值</span>。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">两个<span class="g-underline-text">目标</span>，C<span class="g-underline-text">值</span>越大意味着<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>越重要(相对于<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>)</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            ￡鱼=W，Sbw，苎—里=w，sww。其中￡上～c．』、_里为样本投影后的广义散度差矩阵，C是正常数，用来平衡最大化类间散度和最小化类内散度<span class="g-font-color green">两个目标，C值越大意味着最小化类内散度越重要(相对于最大化类间散度)</span>。最大散度差准则函数的物理意义是投影变换后特征空间的样本具有最大类间散度和最小类内                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《一种基于散度差准则的人脸鉴别分析方法》<br><b>作者：</b>马文莹<br><b>作者单位：</b>淄博职业学院 山东淄博 255000<br><b>参考文献：</b>4篇<br><b>页数：</b>1页<br><b>分类号：</b>TP391.41<br><b>机标分类号：</b>TP3 TN9<br><b>期刊名称：</b>《科技资讯》<br><b>出版时间：</b>2013年6期<br><b>ISSN：</b>1672-3791<br><b>关键词：</b>最大散度差 特征向量 大间距线性投影 人脸鉴别<br><b>摘要：</b>本文提出一种基于散度差准则的人脸鉴别分析方法.最大散度差利用样本模式的类间散布与类内散布之差(Sb-C*Sw)大特征值对应的特征向量,而不是它们的熵比作为鉴别准则,这样,从根本上避免了奏类散布矩阵奇异带来的困难.另外,分析了当参数C趋向无穷大时,最大散度差分类器的极限情况,得到了大间距线性投影分类器.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术会议">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">13</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">45%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优化准则，它要求目标最小化<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，同时最大化<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>瓯中<span class="g-underline-text">的</span>彳，权重信息相当于<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>归一化处理，<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>鼠</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            考虑，将类间散度矩阵最和类内散度矩阵＆重新定义，其形式如下：&=耘其中tj是表明在第i类中，除J这个样本的任意其它样本。从公式(6，7)可以看出，<span class="g-font-color green">类内散度矩阵瓯中的彳，权重信息相当于类内散度矩阵归一化处理，类间散度矩阵鼠</span>直接归一化。这种处理借鉴了规则化思想，可以有效地克服类内存在Outlier或者类间距离不均的样本分布，从而                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术会议）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《规则化的线性鉴别分析算法》<br><b>作者：</b>郭礼华 金连文<br><b>作者单位：</b>华南理工大学电子与信息学院,广州,510641<br><b>会议名称：</b>2010年全国模式识别学术会议(CCPR2010)<br><b>主办单位：</b>中国图象图形学学会<br><b>会议时间：</b>2010-10-21<br><b>会议地点：</b>重庆<br><b>关键词：</b>线性鉴别分析 规则化 多模态
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">14</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">45%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优<span class="g-underline-text">化</span>准则，它<span class="g-underline-text">要求</span>目标<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，同时<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">w，使得投影后<span class="g-underline-text">的</span>样本yAw满足<span class="g-underline-text">最大</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>和<span class="g-underline-text">最小</span><span class="g-underline-text">化</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span><span class="g-underline-text">要求</span>。</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            量。设c类训练样本集图像为A1，A2，⋯，AN，本的总个数。第i类训练目标有Ni个样本，jAi为第i类的第j个样本。2DLDA的目标是找到一个投影轴<span class="g-font-color green">w，使得投影后的样本yAw满足最大化类间散度矩阵和最小化类内散度矩阵的要求。</span>由于投影后样本的散布情况可通过样本协方差矩阵的迹来描述，故采用下面的准则函数电子科技大学硕士学位                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于核函数的SAR图像目标识别研究》<br><b>作者：</b>田兵兵<br><b>学科专业：</b>信息与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>周代英<br><b>学位授予单位：</b>电子科技大学<br><b>学位年度：</b>2015
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">15</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">45%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优化准则，它要求目标最小化<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，同时最大化<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span>零空<span class="g-underline-text">间</span>会<span class="g-underline-text">间</span>接地丢失<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span>零空<span class="g-underline-text">间</span>，而<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span>零</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            f为非奇异，但是通过扰动项会带来更多的随机性和不确定性；3)直接法：Yu等人指出类间散度矩阵的零空间中不包含任何判别信息，通过丢弃类问散度矩阵的零空间，提出了DLDA类<span class="g-font-color green">间散度矩阵的零空间会间接地丢失类内散度矩阵的零空间，而类内散度矩阵的零</span>空间包含最具有判别特性的信息，类似的还有DLPP(directlocality该算法在类内散度矩阵的零空间内寻找                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《人脸识别中适合于小样本情况下的监督化拉普拉斯判别分析》<br><b>作者：</b>楼宋江 张国印 潘海为 王庆军<br><b>作者单位：</b>哈尔滨工程大学计算机科学与技术学院  哈尔滨  150001<br><b>参考文献：</b>21篇<br><b>被引次数：</b>2次（统计时间：2015年8月）<br><b>页码：</b>P1730—P1737<br><b>分类号：</b>TP391.41<br><b>机标分类号：</b>TP3 TP1<br><b>基金项目：</b>国家自然科学基金(60803036)<br><b>期刊名称：</b>《计算机研究与发展》<br><b>出版时间：</b>2012年8期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1000-1239<br><b>关键词：</b>特征提取 人脸识别 保局算法 无监督判别投影 监督化拉普拉斯判别分析 小样本问题<br><b>摘要：</b>提取有效特征对高维数据的模式分类起着关键的作用.无监督判别投影,通过最大化非局部散度和局部散度之比,在数据降维和特征提取上表现出较好的性能,但是它是一种非监督学习算法,并且存在小样本问题.针对这些问题,提出了监督化拉普拉斯判别分析,算法在考虑非局部散度和局部散度时考虑了样本的类别信息；通过丢弃总体拉普拉斯散度矩阵的零空间,并将类内拉普拉斯散度矩阵投影到总体拉普拉斯散度矩阵的主空间中,然后在该空间中进行特征问题的求解,从而避免了小样本问题.通过理论分析,该算法没有任何判别信息损失,同时在计算上效率也较高.在人脸识别上的实验验证了算法的正确性和有效性.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">16</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">45%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">回顾LDA<span class="g-underline-text">的</span>优化准则，它要求目标最小化<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值，同时最大化<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>值。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">）<span class="g-underline-text">的</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span>定义沿用LDA算法<span class="g-underline-text">的</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>定义，而<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">的</span>定义</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            决小样本问题下的NDA类内散度为零问题；同时提出零空间非参数子空间分析的方法零空间中的判别信息。2.2.5.1两类别非参数判别分析两类别非参数判别分析（Two-classNDA<span class="g-font-color green">）的类内散度矩阵的定义沿用LDA算法的类内散度矩阵定义，而类间散度矩阵的定义</span>则与之不同，其具体定义如下：万方数据基于最坏分离和平均紧性的判别分析探究其中il表示第i类                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于最坏分离和平均紧性的判别分析探究》<br><b>作者：</b>杨磊磊<br><b>分类号：</b>TP301.6<br><b>学科专业：</b>计算机科学与技术<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>陈松灿<br><b>学位授予单位：</b>南京航空航天大学<br><b>学位年度：</b>2014<br><b>关键词：</b>低分辨率图像 线性判别 最坏分离 平均紧性 联合分辨率 识别算法
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
            
        <!--语句修改建议-->
        <span id="modify_suggest"></span>
        <div id="advice">
            <div class="g-line-row"></div>
            <div class="paper-txt P30 PB0">
                <div class="paper-section">
                    <p class="g-font-s16 font-bold g-font-color green MB10">该句修改建议（轻度相似，请酌情修改）</p>
                    <span class="g-font-color green">回顾LDA的优<span class="g-font-color red">化</span>准则，它要求目标<span class="g-font-color red">最小</span><span class="g-font-color red">化</span><span class="g-font-color red">类</span><span class="g-font-color red">内</span><span class="g-font-color red">散</span><span class="g-font-color red">度</span><span class="g-font-color red">矩阵</span>值，同时<span class="g-font-color red">最大</span><span class="g-font-color red">化</span><span class="g-font-color red">类</span><span class="g-font-color red">间</span><span class="g-font-color red">散</span><span class="g-font-color red">度</span><span class="g-font-color red">矩阵</span>值。</span>
                    <div class="MT10">
                        <p class="font-bold">同义词：</p>
                        <ul class="local-source-detail">
                            
                        </ul>

                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="back-to-top text-center">
        <a href="#gototop" class="font-bold g-font-color green">回到顶部</a>
    </div>
    <div class="paper-footer">
        <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
        <p>Copyright © 2007-2018 PaperPass</p>
    </div>
</div>
</body>
<script type="text/javascript" src="../js/jquery.min.js"></script>
<script type="text/javascript" src="../js/Lib.js"></script>
<script type="text/javascript">
    (function(System,$){
        var tab = System.Paper.tab();
        var $advice = null;
        function run(){
            var i = 0;
            $advice.show();
            tab.call(this,{callback:function(){
                var $num = $(this).find('.chapter-num');
                if($num.length>0){
                    i++;
                    $num.text(i);
                }
            }});
            //没有内容时同时不显示该句修改建议
            if(0 === i){$advice.hide();}
        }
        $(function(){
            $advice = $('#advice');
            $(document).on('click','[tab-a="ul"] li',function(){
                run.call(this);
            });
            $(document).on('click','[tab-b="ul"] li',function(){
                run.call(this);
            });
        });
    })(Report,jQuery);


</script>
</html>
