<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>详细报告语句详情</title>
    <link href="../css/bootstrap.css" rel="stylesheet" />
    <link href="../css/style.css" rel="stylesheet" />
    <style type="text/css">
        .content-tips .paper-section{margin-bottom:0;min-width:450px;}
    </style>
</head>
<body>
<span id="gototop"></span>
<div>
    <div class="paper-txt P30">
        <div class="paper-section" style="margin-bottom:0;">
            <div class="font-bold MT5">
                该句相似度：<span class="g-font-color orange similarNum">51%</span>
            </div>
            <div class="MT30">
                <p class="font-bold">您的语句：</p>
                <span>由于类间散度矩阵，类内散度矩阵和总散度矩阵紧密相关，所以原始LDA可以导出许多变化。</span>
            </div>
        </div>
    </div>
    <div>
        <div class="tab-A">
            <ul class="tab-A-ul clearfix" tab-a="ul">
                <li class="active" data-id="学术期刊,学位论文,学术会议,书籍数据,互联网,自建库,all">
                    <span class="tab-text">综合</span>
                    <span class="tab-superscript">16</span>
                </li>
                <li data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local">
                    <span class="tab-text">本地库</span>
                    <span class="tab-superscript">16</span>
                </li>
                <li data-id="互联网,5">
                    <span class="tab-text">互联网</span>
                    <span class="tab-superscript">0</span>
                </li>
            </ul>
        </div>
        <div class="none" tab="section" data-id="tab">
            <div class="tab-B clearfix">
                <div class="paper-section P30 PB0 clearfix">
                    <span class="tab-B-span pull-left">本地库</span>
                    <ul class="tab-B-ul pull-left clearfix" tab-b="ul">
                        <li class="active" data-id="tab,学术期刊,学位论文,学术会议,书籍数据,自建库,local">
                            <span class="tab-text">全部</span>
                            <span class="tab-superscript">16</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术期刊,1">
                            <span class="tab-text">期刊</span>
                            <span class="tab-superscript">5</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学位论文,2">
                            <span class="tab-text">学位</span>
                            <span class="tab-superscript">9</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,学术会议,3">
                            <span class="tab-text">会议</span>
                            <span class="tab-superscript">2</span>
                            <span class="black-spacer"></span>
                        </li>
                        <li data-id="tab,书籍数据,4">
                            <span class="tab-text">图书</span>
                            <span class="tab-superscript">0</span>
                                                    </li>
                                            </ul>
                </div>
                <div class="g-line-row MT30 tab-pane-line"></div>
            </div>
        </div>
        <div class="content-tips">
            <div class="tab-content none" tab="section" data-id="1">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在期刊库共找出相似内容：<span>5</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                </div>
            </div>

            <div class="tab-content none" tab="section" data-id="2">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在学位库共找出相似内容：<span>9</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="3">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在会议库共找出相似内容：<span>2</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>                    </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="4">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在图书库中没有找到与此句话相似的内容                    <p>
                    <div class="pull-right">
                                            </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="5">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在互联网库中没有找到与此句话相似的内容                    <p>
                    <div class="pull-right">
                                            </div>
                </div>
            </div>
            <!-- 自建库 -->
            <div class="tab-content none" tab="section" data-id="6">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在自建库中没有找到与此句话相似的内容                    <p>
                    <div class="pull-right">
                                            </div>
                </div>
            </div>
                        <div class="tab-content" tab="section" data-id="all">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在本地库和互联网库共找出相似内容：<span>16</span>个
                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>

                    </div>
                </div>
            </div>
            <div class="tab-content none" tab="section" data-id="local">
                <div class="paper-txt P30 paper-section clearfix">
                    <p class="g-font-color green pull-left">
                        在本地库共找出相似内容：<span>16</span>个                    <p>
                    <div class="pull-right">
                        <a href="#modify_suggest" class="g-btn g-btn-default g-btn-sm">查看修改意见</a>
                    </div>
                </div>
            </div>
        </div>



                <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">1</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">51%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>、<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总体<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>。另外，为了避免<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span>的奇异，</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            说明了基于图像矩阵的线性鉴别分析在特征提取的速度方面和节约内存空间方面有了显著的提高。Yang[45l还提出直接基于图像矩阵的图像投影技术(即2DPCA)，它是直接基于图像矩阵构建构样本的<span class="g-font-color green">类内散度矩阵、类间散度矩阵和总体散度矩阵。另外，为了避免类内散度的奇异，</span>一种称为PCAplusLDA的两阶段的线性鉴别方法被提出郴删；该方法首先是利用基于图像矢量的PCA对图像进行降维                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《线性子空间人脸识别方法的研究与仿真》<br><b>作者：</b>陈满<br><b>分类号：</b>O241.6<br><b>学科专业：</b>测试计量技术及仪器<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>李勇智<br><b>学位授予单位：</b>南京林业大学<br><b>学位年度：</b>2007<br><b>关键词：</b>人脸识别 图像矩阵 特征提取 图像子空间法 分块MMC 独立成份分析 核ICA
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">2</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">49%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>和<span class="g-underline-text">总</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>：<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>：c肌<span class="g-underline-text">总</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>：其中：置2袁荟tJj2袁荟</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            第歹个d维的样本，对人脸图像而言，通常是将图像按列或行拉直成向量，因此d通常较大．类间散度矩阵瓯、类内散度矩阵S。和总散度矩阵S。定义如下：<span class="g-font-color green">类间散度矩阵：类内散度矩阵：c肌总散度矩阵：其中：置2袁荟tJj2袁荟</span>荟工t。作者简介：刘晓亮(1983-)，男，硕士研究生，主要研究方向为信号与图像处理．万方                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《一种加权的核Fisher鉴别分析在人脸识别中的应用》<br><b>作者：</b>刘晓亮 王福龙 黄诚 曾爱华<br><b>作者单位：</b>广东工业大学,应用数学学院,广东,广州,510006<br><b>参考文献：</b>10篇<br><b>被引次数：</b>2次（统计时间：2015年8月）<br><b>页码：</b>P65—P69<br><b>页数：</b>5页<br><b>分类号：</b>TP391<br><b>机标分类号：</b>TP3 TN9<br><b>期刊名称：</b>《广东工业大学学报》<br><b>出版时间：</b>2009年4期<br><b>期刊级别：</b>ISTIC<br><b>ISSN：</b>1007-7162<br><b>关键词：</b>人脸识别 Fisher非线性鉴别分析 最大散度差鉴别准则<br><b>摘要：</b>在非线性空间中采用加权的最大散度差鉴别准则函数,该方法不仅有效地抽取了人脸图像的非线性特征,而且在特征空间H中,使用权函数重新构造了类间散度矩阵和类内散度矩阵,从而优化了核的最大散度差准则函数.最后在ORL和Yale人脸数据库上的实验结果验证了本文方法的有效性.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">3</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">48%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">得到<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>。上述问题会成为求解LDA算法<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            从不同的9个角度拍摄的人脸数据，在LDA算法的公式中体现的值就是c130，size()9i，接下来要通过求解130个()dd矩哈尔滨工业大学工学硕士学位论文阵连续相加来<span class="g-font-color green">得到类间散度矩阵和类内散度矩阵。上述问题会成为求解LDA算法类内散度矩阵和类间</span>散度矩阵的主要瓶颈。在实际应用中，数据的原始维度d可能很大，从公式（2-14）和公式                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于GPU的并行线性判别分析算法研究》<br><b>作者：</b>孔昭阳<br><b>分类号：</b>TP301.6<br><b>学科专业：</b>计算机科学与技术<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>叶允明<br><b>学位授予单位：</b>哈尔滨工业大学<br><b>学位年度：</b>2014<br><b>关键词：</b>线性判别分析 LDA算法 CPU-GPU异构计算 广义特征问题
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术会议">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">4</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">46%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA<span class="g-underline-text">可以</span>导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">2)中<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>&<span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>S。的定义，<span class="g-underline-text">可以</span>看出，<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            看出，LDA所得到的投影矩阵并非最佳的投影矩阵。文献哺1针对这个问题提出了一套解决方案，但是整体的运算复杂度高，针对大样本数据的时候，LDA投影矩阵的计算非常耗时。重新审视公式(<span class="g-font-color green">2)中类间散度矩阵&和类内散度矩阵S。的定义，可以看出，类间散度</span>矩阵S定义中并没有将得到的距离进行归一化处理；同样类内散度矩阵鼠，的定义也没有考虑                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术会议）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《规则化的线性鉴别分析算法》<br><b>作者：</b>郭礼华 金连文<br><b>作者单位：</b>华南理工大学电子与信息学院,广州,510641<br><b>会议名称：</b>2010年全国模式识别学术会议(CCPR2010)<br><b>主办单位：</b>中国图象图形学学会<br><b>会议时间：</b>2010-10-21<br><b>会议地点：</b>重庆<br><b>关键词：</b>线性鉴别分析 规则化 多模态
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">5</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">46%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span>间<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">类</span>问<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总体<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>：挑∑Ⅲ●一Ⅳ●一Ⅳ一瓯</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            数据库上的识别实验证实本文算法的有效性．2Fisher准则函数和Fisher极小准则函数假设训练集共有C个类别，每类有巩个样本，共有N个样本，每个样本为一个d维向量，则该数据集的<span class="g-font-color green">类问散度矩阵，类内散度矩阵和总体散度矩阵：挑∑Ⅲ●一Ⅳ●一Ⅳ一瓯</span>瓯万方数据模式识别与人工智能26卷其中，m和mi分别为全体样本及第i类样本的平均并且3个散                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《Fisher极小准则不相关空间算法及其在人脸识别中的应用》<br><b>作者：</b>杨军 刘妍丽 冯朝胜 冯林<br><b>作者单位：</b>四川师范大学计算机科学学院 成都610101；四川大学计算机学院图形图像研究所 成都610064；四川师范大学数学与软件科学学院 成都610101<br><b>参考文献：</b>13篇<br><b>页码：</b>P598—P603<br><b>页数：</b>6页<br><b>分类号：</b>TP391.41<br><b>机标分类号：</b>O15 F51<br><b>基金项目：</b>国家自然科学基金项目(60736046);国家973计划项目(2009CB320803);四川省教育厅科研项目(11ZB069)<br><b>期刊名称：</b>《模式识别与人工智能》<br><b>出版时间：</b>2013年6期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1003-6059<br><b>关键词：</b>Fisher极小准则 不相关鉴别矢量集 不相关空间算法 小样本问题<br><b>摘要：</b>不相关空间算法是一种基于广义Fisher准则求解不相关鉴别矢量集的快速算法,但该算法要求总体散度矩阵可逆.针对高维小样本的情况,文中提出求解不相关鉴别矢量集的改进方法.该方法的基本思路是在类间散度矩阵的值空间中运用广义Fisher极小准则求解鉴别矢量集,并讨论在该子空间中进行求解的合理性.针对高维情况下类间散度矩阵值空间的计算效率问题,提出首先利用PCA算法将数据降维,然后在低维空间中求解值空间的策略并讨论其合理性.在ORL人脸数据库上的实验验证该方法的有效性,其识别率高于传统的Fisher脸方法和不相关空间算法.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">6</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">45%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">的<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>%<span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>品大小远远小于FLD<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>品<span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            这里对于一个NxM维的图像矩阵，其类间散度矩阵岛和类内散度矩阵。%的大小应该是NxN，[1百FLD的类间散度矩阵品和类内散度矩阵品的大小是NMxNM，因此2DFLD<span class="g-font-color green">的类间散度矩阵%和类内散度矩阵品大小远远小于FLD类间散度矩阵品和类内散</span>度矩阵品的大小，处理式(4．6)中的特征值问题也容易很多。实际上在样本类别数                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《掌纹图像处理及识别方法研究》<br><b>作者：</b>许爽<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>通信与信息系统<br><b>授予学位：</b>博士<br><b>导师姓名：</b>索继东<br><b>学位授予单位：</b>大连海事大学<br><b>学位年度：</b>2012<br><b>关键词：</b>掌纹图像 定位分割 线性降维 Gabor变换
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">7</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">44%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>和总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">方法<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>与<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>的引入，受<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>奇异的限制，小样本</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            空间和主空间的思想，与直接LDA法不同的就是它是先分别求出零空间和主空间中的向量，再把它们融合。虽然这些方法都在一定程度上能解决小样本问题[33][34]，但由于LDA<span class="g-font-color green">方法类间散度矩阵与类内散度矩阵的引入，受类内散度矩阵奇异的限制，小样本</span>问题始终不能从本质上解决。况且此方法是针对向量的，在使用时需将图像矩阵拉成向量，没有保持                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《二维核主成分分析算法和应用研究》<br><b>作者：</b>郑颖<br><b>分类号：</b>TP301.6<br><b>学科专业：</b>数学<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>周水生<br><b>学位授予单位：</b>西安电子科技大学<br><b>学位年度：</b>2014<br><b>关键词：</b>人脸识别 矩阵分解 特征提取 二维核主成分分析算法 数据库
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">8</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">43%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span>间<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">上对<span class="g-underline-text">类</span>间离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span>离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>进行标量化处理。经典LDA中<span class="g-underline-text">类</span>间离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span><span class="g-underline-text">类</span></p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            Sw是奇异的，此种情况称为小样本问题。在Sw奇异的情况下，已有的解决办法可以参考文献[15-16]。3改进的算法（ILDA）为了降低运算量，提高运算效率，ILDA在经典LDA的基础<span class="g-font-color green">上对类间离散度矩阵和类内离散度矩阵进行标量化处理。经典LDA中类间离散度矩阵和类</span>内离散度矩阵对应的标量表达式分别为：式中k表示样本空间的维度。式（7）各维加权                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《改进的LDA算法及秩限制问题研究》<br><b>作者：</b>刘忠宝 王士同<br><b>作者单位：</b>江南大学,信息学院,江苏,无锡,214122；山西大学,商务学院信息工程系,太原,030031<br><b>参考文献：</b>18篇<br><b>页码：</b>P17—P20<br><b>分类号：</b>TP391.4<br><b>机标分类号：</b>TP3 TP1<br><b>基金项目：</b>国家高技术研究发展计划(863);国家自然科学基金;江苏省六大人才高峰计划;江苏省研究生创新计划课题<br><b>期刊名称：</b>《计算机工程与应用》<br><b>出版时间：</b>2010年32期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1002-8331<br><b>关键词：</b>线性判别分析 类间离散度矩阵 类内离散度矩阵 秩限制问题<br><b>摘要：</b>针对经典线性判别分析中存在的秩限制和小样本问题,通过改进原有的Fisher准则,提出了一种改进的线性判别分析算法ILDA,以克服秩限制问题并同时解决了小样本问题.重点研究了ILDA在解决样本类间离散度矩阵秩限制方面的有效性.在多个国际标准数据集和人工数据集上实验的结果表明ILDA算法不仅有效地突破了秩限制,达到提取更多判别特征的目的,而且具有良好的识别效果.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">9</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">42%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>和总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">了<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>与<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>之差作为准则，从而避免了<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>奇异这一</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            、计算量也小、散布矩阵一般情况下可逆等优点．结合二维图像投影理论与最大间距准则方法的二维最大2DⅫMC)算法由于是直接基于图像矩阵的所以在极大程度上提升了特征提取的速度，而且由于采用<span class="g-font-color green">了类间散度矩阵与类内散度矩阵之差作为准则，从而避免了类内散度矩阵奇异这一</span>问题．因为二维最大间距准则仍旧是全局线性方法，提取收稿日期：2015-0|6-24收修改稿日期：                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《分块二维最大间距准则的特征提取方法》<br><b>作者：</b>万鸣华 卢桂馥<br><b>作者单位：</b>东南大学信息科学与工程学院,南京210096；南京理工大学高维信息智能感知与系统教育部重点实验,南京210094；东南大学信息科学与工程学院,南京,210096<br><b>参考文献：</b>19篇<br><b>页码：</b>P2088—P2092<br><b>页数：</b>5页<br><b>分类号：</b>TP391<br><b>基金项目：</b>国家自然科学基金项目(61462064,61203243);江西省自然科学基金项目(20122BAB211025);高维信息智能感知与系统教育部重点实验室(南京理工大学)基金项目(30920140122006);中国博士后基金项目(2014T70453,2013M530223);江苏省博士后基金项目(1301095C)<br><b>期刊名称：</b>《小型微型计算机系统》<br><b>出版时间：</b>2016年9期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1000-1220<br><b>关键词：</b>二维最大间距准则 分块二维最大间距准则 人脸识别 特征提取<br><b>摘要：</b>针对二维最大间距准则(Two Dimensional Maximum Margin Criterion,2DMMC)算法进行特征提取时,无法提取局部的特征.同时,该算法也受不同的表情、光照以及姿态等条件的影响,识别的效果也大大降低.因此,提出一种基于分块二维MMC(Modular Two Dimensional Maximum Margin Criterion,M2DMMC)的人脸识别方法.首先,对图像矩阵进行分块,然后对分块后的矩阵进行2DMMC特征抽取,对每一子块抽取的特征进行整体融合,最后采用最近邻判决准则进行分类识别.在ORL,Yale人脸图像库进行实验的结果表明,新算法相对于MMC算法、二维MMC算法以及分块MMC算法均有较好的识别性能.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">10</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">42%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA<span class="g-underline-text">可以</span>导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">的秩能够测量<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>的距离[62]，其表达式<span class="g-underline-text">可以</span>表述为以下</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            尽量的高。也就是说类内散度矩阵Jw的数值尽量最小，类间散度矩阵Jb的数值尽量的最大，wmin，其中Tr表示矩阵的秩，代表矩阵数值的大小。散度矩阵<span class="g-font-color green">的秩能够测量类内散度矩阵和类间散度矩阵的距离[62]，其表达式可以表述为以下</span>方式：w来测量类内样本的紧密程度，而Tr()Jb测量的是类间样本的耦合程度。因此                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《非负矩阵分解及在基因表达数据分析中的应用研究》<br><b>作者：</b>马春霞<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>信息与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>刘金星<br><b>学位授予单位：</b>曲阜师范大学<br><b>学位年度：</b>2015<br><b>关键词：</b>基因表达 数据分析 聚类分析 特征基因提取 非负矩阵分解
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">11</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">41%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>和总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>bS与<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>Sw：计算<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>与<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>之差</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            样本子块的平均值矩阵j然后求得设第i类样本子块均值均值为i则所有训练样本子块的平均值矩阵:则所有训练样本子块的散度矩阵S为:则可以求得所有训练样本子块的<span class="g-font-color green">类间散度矩阵bS与类内散度矩阵Sw：计算类间散度矩阵与类内散度矩阵之差</span>SbSw的特征值与特征矩阵，将特征值按照从大到小顺序排列，选取前面的d个最大的特征                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于分块的人脸特征提取与识别研究》<br><b>作者：</b>刘辉<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>电子与通信工程<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>万鸣华<br><b>学位授予单位：</b>南昌航空大学<br><b>学位年度：</b>2015<br><b>关键词：</b>人脸识别 特征提取 主成分分析 线性鉴别分析 最大间距准则
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">12</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">41%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange"><span class="g-underline-text">由于</span><span class="g-underline-text">类</span>间<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>和总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，<span class="g-underline-text">所以</span>原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green"><span class="g-underline-text">由于</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span>离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>的秩通常大于<span class="g-underline-text">类</span>间离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>的秩，<span class="g-underline-text">所以</span><span class="g-underline-text">类</span>间离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>满秩的同时也</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            最大的特征再求类内离散度最小的特征，或者先求类内离散度最小再求类间离散度最大，这其中也都涉及空间舍弃的问题，比如在DLDA中，首先舍弃了类间离散度矩阵的零空间，<span class="g-font-color green">由于类内离散度矩阵的秩通常大于类间离散度矩阵的秩，所以类间离散度矩阵满秩的同时也</span>导致了类内离散度矩阵的满秩，丢失了类内离散度矩阵零空间中所包含的部分辨别信息。由Fisher线性                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《红外图像人脸识别方法研究》<br><b>作者：</b>曹凤杰<br><b>分类号：</b>TN219<br><b>学科专业：</b>物理电子学<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>徐军<br><b>学位授予单位：</b>西安电子科技大学<br><b>学位年度：</b>2010<br><b>关键词：</b>红外图像 人脸识别 特征提取 压缩感知 特征校正
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">13</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">41%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">的<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>分别为：瓦：善等fl-≥I善c善◇卜鸭炒</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            的训练样本数目。LDA的目标是使得低维空间中的类内样本的分布尽可能紧凑(类内散度最小)，同时又使得类间样本的距离尽可能地分开(类间散度最大)。定义在低维样本<span class="g-font-color green">的类间散度矩阵和类内散度矩阵分别为：瓦：善等fl-≥I善c善◇卜鸭炒</span>|；，一所，)r@J叻其中∥是第，类人脸中的第_『个样本的低维                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于小波变换和线性子空间的人脸识别技术研究》<br><b>作者：</b>彭宇翔<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>电子信息技术及仪器<br><b>授予学位：</b>硕士<br><b>导师姓名：</b>王友钊<br><b>学位授予单位：</b>浙江大学<br><b>学位年度：</b>2012<br><b>关键词：</b>人脸识别 Haar特征 Adaboost分类器 小波变换 抽样重组
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术会议">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">14</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">40%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span>间<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>和总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">为<span class="g-underline-text">类</span>间离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>与<span class="g-underline-text">类</span><span class="g-underline-text">内</span>离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>逆阵构成。而<span class="g-underline-text">类</span><span class="g-underline-text">内</span>离<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>一般为满秩方阵，因此</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            实际的数据测试结果说明，通过选择适当的x可以得到比较理想的类内类间距离比。但是否能找到一种比较合理的确定x的方法．使得探测较少的次数就可以确定x的值。其次，由于产生矩阵<span class="g-font-color green">为类间离散度矩阵与类内离散度矩阵逆阵构成。而类内离散度矩阵一般为满秩方阵，因此</span>，改进后的产生矩阵一般也为满秩方阵，这样也会出现可分性信息会比较分散的问题．就数据                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术会议）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《K-L变换中产生矩阵分析》<br><b>作者：</b>徐戈 唐依珠 刘传才<br><b>作者单位：</b>福州大学计算机科学与技术系(福州)<br><b>会议名称：</b>2001年全国理论计算机科学学术会议<br><b>主办单位：</b>中国计算机学会<br><b>会议时间：</b>2001-09-01<br><b>会议地点：</b>福州<br><b>关键词：</b>K-L变换 模式识别 综合离散度矩阵 产生矩阵分析
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学术期刊">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">15</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">40%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">后。为计算<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>时的近邻个数，a为零到无穷大的常数</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            数据，ⅣⅣp(戈：，J)表示戈；到第J类训练样本中的第p个最近邻样本，d(%口：)=、/可弄丽表示向量”。和秽：之间的欧氏距离，后。和<span class="g-font-color green">后。为计算类间散度矩阵和类内散度矩阵时的近邻个数，a为零到无穷大的常数</span>，用来调节权值(cJ(i，i，p，f)随着式(6)的近邻样本欧氏距离比值的变化                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学术期刊）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《两向二维NFA及其在SAR目标识别中的应用》<br><b>作者：</b>刘振 姜晖 王粒宾<br><b>作者单位：</b>解放军电子工程学院,合肥,230037；解放军61922部队,北京,100094<br><b>参考文献：</b>14篇<br><b>页码：</b>P151—P155<br><b>页数：</b>5页<br><b>分类号：</b>TP751<br><b>机标分类号：</b>TP3 O23<br><b>期刊名称：</b>《火力与指挥控制》<br><b>出版时间：</b>2014年2期<br><b>期刊级别：</b>ISTIC - PKU<br><b>ISSN：</b>1002-0640<br><b>关键词：</b>合成孔径雷达 目标识别 线性鉴别分析 非参数特征分析<br><b>摘要：</b>通过对传统线性鉴别分析局限性的分析,提出一种基于两向二维非参数特征分析((2D)2NFA)的SAR图像目标识别方法,该方法有效克服了线性鉴别分析的固有缺陷并且运算量也大大降低.首先,定义一种图像矩阵的近邻样本选取方法,继而利用k近邻样本构造(2D)2NFA的类间散度矩阵和类内散度矩阵,然后使用(2D)2NFA提取样本的特征,最后在特征空间中使用简单的最近邻分类器进行待识别测试目标的分类识别.用美国运动和静止目标获取与识别(MSTAR)计划录取的SAR图像数据进行了仿真实验,实验结果表明(2D)2NFA增强了提取特征的可鉴别性,能够获得更高的识别率,而且减小了特征维数.
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
                    <div class="tab-content" tab="section" data-id="学位论文">
            <div>
                <div class="g-line-row"></div>
                <div class="paper-txt P30">
                    <div class="paper-section" style="margin-bottom:0;">
                        <div class="clearfix">
                            <div class="pull-left">
                                <span class="chapter-symbol"></span>
                                <span class="chapter-num">16</span>

                            </div>
                            <div class="font-bold pull-right">
                                相似度：<span class="g-font-color orange similarNum">40%</span>
                            </div>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">您的句子：</p>
                            <p class="g-font-color orange">由于<span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>，<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span><span class="g-underline-text">和</span>总<span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</p>

                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似句子：</p>
                            <p class="g-font-color green">，<span class="g-underline-text">和</span><span class="g-underline-text">类</span><span class="g-underline-text">间</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>&；第二步：设<span class="g-underline-text">类</span><span class="g-underline-text">内</span><span class="g-underline-text">散</span><span class="g-underline-text">度</span><span class="g-underline-text">矩阵</span>的秩rank(S。)=，．</p>
                        </div>
                        <div class="MT10">
                            <p class="font-bold">相似原文片段：</p>
                            的信息。5．2．5零空间法要思想是在类内散度矩阵的零空间内寻找最大化类间散度矩阵的最优特征向量。算法步骤简述如下：第一步：计算样本的类内散度矩阵S。<span class="g-font-color green">，和类间散度矩阵&；第二步：设类内散度矩阵的秩rank(S。)=，．</span>，如果厂=N，则此时S。是可逆的，直接求解SwlS的最大特征值所对应的特征向量作为投影矩阵                        </div>
                        <div class="MT10">
                            <p class="font-bold">来源（学位论文）：</p>
                            <div class="local-source-detail">
                                <b>篇名：</b>《基于保局子空间分析的人脸特征提取算法研究》<br><b>作者：</b>楼宋江<br><b>分类号：</b>TP391.41<br><b>学科专业：</b>检测技术与自动化装置<br><b>授予学位：</b>博士<br><b>导师姓名：</b>张国印<br><b>学位授予单位：</b>哈尔滨工程大学<br><b>学位年度：</b>2011<br><b>关键词：</b>人脸识别 特征提取 局部保持投影算法 小样本问题 子空间分析
                            </div>
                        </div>
                    </div>
                </div>

            </div>

        </div>
            
        <!--语句修改建议-->
        <span id="modify_suggest"></span>
        <div id="advice">
            <div class="g-line-row"></div>
            <div class="paper-txt P30 PB0">
                <div class="paper-section">
                    <p class="g-font-s16 font-bold g-font-color green MB10">该句修改建议（轻度相似，请酌情修改）</p>
                    <span class="g-font-color green">由于<span class="g-font-color red">类</span><span class="g-font-color red">间</span><span class="g-font-color red">散</span><span class="g-font-color red">度</span><span class="g-font-color red">矩阵</span>，<span class="g-font-color red">类</span><span class="g-font-color red">内</span><span class="g-font-color red">散</span><span class="g-font-color red">度</span><span class="g-font-color red">矩阵</span>和总<span class="g-font-color red">散</span><span class="g-font-color red">度</span><span class="g-font-color red">矩阵</span>紧密相关，所以原始LDA可以导出许多变化。</span>
                    <div class="MT10">
                        <p class="font-bold">同义词：</p>
                        <ul class="local-source-detail">
                            
                        </ul>

                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="back-to-top text-center">
        <a href="#gototop" class="font-bold g-font-color green">回到顶部</a>
    </div>
    <div class="paper-footer">
        <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
        <p>Copyright © 2007-2018 PaperPass</p>
    </div>
</div>
</body>
<script type="text/javascript" src="../js/jquery.min.js"></script>
<script type="text/javascript" src="../js/Lib.js"></script>
<script type="text/javascript">
    (function(System,$){
        var tab = System.Paper.tab();
        var $advice = null;
        function run(){
            var i = 0;
            $advice.show();
            tab.call(this,{callback:function(){
                var $num = $(this).find('.chapter-num');
                if($num.length>0){
                    i++;
                    $num.text(i);
                }
            }});
            //没有内容时同时不显示该句修改建议
            if(0 === i){$advice.hide();}
        }
        $(function(){
            $advice = $('#advice');
            $(document).on('click','[tab-a="ul"] li',function(){
                run.call(this);
            });
            $(document).on('click','[tab-b="ul"] li',function(){
                run.call(this);
            });
        });
    })(Report,jQuery);


</script>
</html>
